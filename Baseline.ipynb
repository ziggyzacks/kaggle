{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import geopy.distance\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import uuid\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import relativedelta\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import holidays\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import xgboost\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle/all\n"
     ]
    }
   ],
   "source": [
    "cd all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(lat1,long1,lat2,long2):\n",
    "    try:\n",
    "        coords_1 = (long1,lat1)\n",
    "        coords_2 = (long2,lat2)\n",
    "\n",
    "        return(geopy.distance.vincenty(coords_1, coords_2).km)\n",
    "    except:\n",
    "        return 'bug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lat_dist(lat1,long1,lat2,long2):\n",
    "    return dist(lat1,long1,lat2,long1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def long_dist(lat1,long1,lat2,long2):\n",
    "    return dist(lat1,long1,lat1,long2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/anaconda3/lib/python3.6/site-packages/geopy/point.py:81: UserWarning: Latitude normalization has been prohibited in the newer versions of geopy, because the normalized value happened to be on a different pole, which is probably not what was meant. If you pass coordinates as positional args, please make sure that the order is (latitude, longitude) or (y, x) in Cartesian terms.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "df['distance']=df.apply(lambda x: dist(x.pickup_latitude,x.pickup_longitude,x.dropoff_latitude,x.dropoff_longitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.distance!='bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['latdistance']=df.apply(lambda x: lat_dist(x.pickup_latitude,x.pickup_longitude,x.dropoff_latitude,x.dropoff_longitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['longdistance']=df.apply(lambda x: long_dist(x.pickup_latitude,x.pickup_longitude,x.dropoff_latitude,x.dropoff_longitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[df.distance!='bug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance</th>\n",
       "      <th>latdistance</th>\n",
       "      <th>longdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.280909</td>\n",
       "      <td>0.301449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>4.64623</td>\n",
       "      <td>2.173992</td>\n",
       "      <td>4.104950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0048</td>\n",
       "      <td>0.329929</td>\n",
       "      <td>0.949115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914154</td>\n",
       "      <td>0.768510</td>\n",
       "      <td>0.495205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36616</td>\n",
       "      <td>0.485836</td>\n",
       "      <td>1.276794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
       "1    2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
       "2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
       "3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
       "4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "\n",
       "   passenger_count  distance  latdistance  longdistance  \n",
       "0                1  0.412061     0.280909      0.301449  \n",
       "1                1   4.64623     2.173992      4.104950  \n",
       "2                2    1.0048     0.329929      0.949115  \n",
       "3                1  0.914154     0.768510      0.495205  \n",
       "4                1   1.36616     0.485836      1.276794  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['fare_amount'].dropna(axis=0, how='any').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999545, 6)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = (df[[ 'pickup_longitude',\n",
    "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "       'passenger_count','distance']]\n",
    "                 .dropna(axis=0, how='any')\n",
    "                 .as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(max_depth=15, max_features=5, n_estimators=100,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
       "           max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=400)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
       "           max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dist(lat1,long1,lat2,long2):\n",
    "    try:\n",
    "        coords_1 = (long1,lat1)\n",
    "        coords_2 = (long2,lat2)\n",
    "\n",
    "        return(geopy.distance.vincenty(coords_1, coords_2).km)\n",
    "    except:\n",
    "        return 'bug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['distance']=df_test.apply(lambda x: dist(x.pickup_latitude,x.pickup_longitude,x.dropoff_latitude,x.dropoff_longitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = (df_test[['pickup_datetime', 'pickup_longitude',\n",
    "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "       'passenger_count','distance']]\n",
    "                 ._get_numeric_data()\n",
    "                 .as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['preds']=predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_keys=df_test[['key','preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final.fare_amount=df_final.merge(df_test_keys,on='key')['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final[['key','fare_amount']].to_csv('results_nathan.csv' ,  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseline_model.pkl']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pickle.dumps(clf)\n",
    "joblib.dump(clf, 'baseline_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MORE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55421320, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pickup_datetime'] = df['pickup_datetime'].str.slice(0, 16)\n",
    "df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    # Extract date attributes and then drop the pickup_datetime column\n",
    "    data['hour'] = data['pickup_datetime'].dt.hour\n",
    "    data['day'] = data['pickup_datetime'].dt.day\n",
    "    data['month'] = data['pickup_datetime'].dt.month\n",
    "    data['year'] = data['pickup_datetime'].dt.year\n",
    "    data['weekday']=data['pickup_datetime'].dt.weekday\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>distance</th>\n",
       "      <th>latdistance</th>\n",
       "      <th>longdistance</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:00</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>0.412061</td>\n",
       "      <td>0.280909</td>\n",
       "      <td>0.301449</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:00</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>4.64623</td>\n",
       "      <td>2.173992</td>\n",
       "      <td>4.104950</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0048</td>\n",
       "      <td>0.329929</td>\n",
       "      <td>0.949115</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:00</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914154</td>\n",
       "      <td>0.768510</td>\n",
       "      <td>0.495205</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36616</td>\n",
       "      <td>0.485836</td>\n",
       "      <td>1.276794</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount     pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5 2009-06-15 17:26:00   \n",
       "1    2010-01-05 16:52:16.0000002         16.9 2010-01-05 16:52:00   \n",
       "2   2011-08-18 00:35:00.00000049          5.7 2011-08-18 00:35:00   \n",
       "3    2012-04-21 04:30:42.0000001          7.7 2012-04-21 04:30:00   \n",
       "4  2010-03-09 07:51:00.000000135          5.3 2010-03-09 07:51:00   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "\n",
       "   passenger_count  distance  latdistance  longdistance  hour  day  month  \\\n",
       "0                1  0.412061     0.280909      0.301449    17   15      6   \n",
       "1                1   4.64623     2.173992      4.104950    16    5      1   \n",
       "2                2    1.0048     0.329929      0.949115     0   18      8   \n",
       "3                1  0.914154     0.768510      0.495205     4   21      4   \n",
       "4                1   1.36616     0.485836      1.276794     7    9      3   \n",
       "\n",
       "   year  weekday  \n",
       "0  2009        0  \n",
       "1  2010        1  \n",
       "2  2011        3  \n",
       "3  2012        5  \n",
       "4  2010        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle/kaggle\n"
     ]
    }
   ],
   "source": [
    "cd kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from process import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('train_with_features.csv')\n",
    "#loading data with precomputed distances\n",
    "dfcut=pd.read_csv('train_with_features.csv',nrows=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:53:17,895 - process - Removing outliers\n"
     ]
    }
   ],
   "source": [
    "#removing outliers\n",
    "data=Process().remove_outliers(dfcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:53:21,534 - process - Extracting date info\n"
     ]
    }
   ],
   "source": [
    "data=Process().split_dates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:53:30,127 - process - Fetching kmeans model\n",
      "2018-08-10 17:53:30,286 - process - Assigning clusters\n"
     ]
    }
   ],
   "source": [
    "data=Process().assign_clusters(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:54:39,097 - process - Adding day density\n"
     ]
    }
   ],
   "source": [
    "data=Process().add_day_density(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:54:47,604 - process - Adding holidays\n"
     ]
    }
   ],
   "source": [
    "data=Process().add_holidays(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickup_density=data[['pickup_cluster']].groupby(data.pickup_cluster).count().add_suffix('_Count').reset_index()\n",
    "dropoff_density=data[['dropoff_cluster']].groupby(data.dropoff_cluster).count().add_suffix('_Count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data.merge(pickup_density, how='left', on='pickup_cluster')\n",
    "data=data.merge(dropoff_density, how='left', on='dropoff_cluster')\n",
    "data['pickup_density'] = data.pickup_cluster_Count\n",
    "data['dropoff_density'] = data.dropoff_cluster_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data[['fare_amount','pickup_longitude',\n",
    "                                      'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "                                      'passenger_count', 'distance', 'year', 'month', 'day', 'hour',\n",
    "                                      'weekday', 'latdistance', 'longdistance', 'holiday', 'day_density',\n",
    "                                      'pickup_cluster', 'dropoff_cluster','pickup_density','dropoff_density']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('process.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-c06f0772bbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'process.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dfcut=pd.read_csv('process.csv',nrows=5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['fare_amount'].dropna(axis=0, how='any').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = (data[[ 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "       'dropoff_latitude', 'passenger_count', 'distance', 'year', 'month',\n",
    "       'day', 'hour', 'weekday', 'latdistance', 'longdistance', 'holiday',\n",
    "       'day_density', 'pickup_cluster_0', 'pickup_cluster_1',\n",
    "       'pickup_cluster_2', 'pickup_cluster_3', 'pickup_cluster_4',\n",
    "       'pickup_cluster_5', 'pickup_cluster_6', 'pickup_cluster_7',\n",
    "       'pickup_cluster_8', 'pickup_cluster_9', 'dropoff_cluster_0',\n",
    "       'dropoff_cluster_1', 'dropoff_cluster_2', 'dropoff_cluster_3',\n",
    "       'dropoff_cluster_4', 'dropoff_cluster_5', 'dropoff_cluster_6',\n",
    "       'dropoff_cluster_7', 'dropoff_cluster_8', 'dropoff_cluster_9','pickup_density','dropoff_density']]\n",
    "                 .dropna(axis=0, how='any')\n",
    "                 .as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9790787,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9790787, 37)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#TO DO: \n",
    "\n",
    "#add holidays\n",
    "#retrain with larger max depth\n",
    "#add features about location zones (kmeans?)\n",
    "#remove absurd outliers (water, etc)\n",
    "#try radius NN\n",
    "#try ANNOY?\n",
    "#try ensembles of above models? add meta learning?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = xgboost.XGBRegressor(max_depth=22, max_features=6, n_estimators=100,n_jobs=-1)\n",
    "#make max depth larger : 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=22, max_features=6, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=-1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4:30\n",
    "#->1h\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI=clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle/kaggle\n"
     ]
    }
   ],
   "source": [
    "cd kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:32:18,777 - process - Fetching kmeans model\n",
      "2018-08-10 17:32:18,785 - process - Assigning clusters\n"
     ]
    }
   ],
   "source": [
    "df_test=Process().assign_clusters(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:32:18,932 - process - Extracting date info\n"
     ]
    }
   ],
   "source": [
    "df_test=Process().split_dates(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        def dist(lat1, long1, lat2, long2):\n",
    "            try:\n",
    "                coords_1 = (long1, lat1)\n",
    "                coords_2 = (long2, lat2)\n",
    "\n",
    "                return (geopy.distance.vincenty(coords_1, coords_2).km)\n",
    "            except:\n",
    "                return 'bug'\n",
    "\n",
    "        def lat_dist(lat1, long1, lat2, long2):\n",
    "            return dist(lat1, long1, lat2, long1)\n",
    "\n",
    "        def long_dist(lat1, long1, lat2, long2):\n",
    "            return dist(lat1, long1, lat1, long2)\n",
    "\n",
    "        df_test['distance'] = df_test.apply(\n",
    "            lambda x: dist(x.pickup_latitude, x.pickup_longitude, x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "        df_test['latdistance'] = df_test.apply(\n",
    "            lambda x: lat_dist(x.pickup_latitude, x.pickup_longitude, x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "        df_test['longdistance'] = df_test.apply(\n",
    "            lambda x: long_dist(x.pickup_latitude, x.pickup_longitude, x.dropoff_latitude, x.dropoff_longitude), axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:32:23,177 - process - Fetching kmeans model\n",
      "2018-08-10 17:32:23,192 - process - Assigning clusters\n"
     ]
    }
   ],
   "source": [
    "df_test=Process().assign_clusters(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:32:23,294 - process - Adding day density\n"
     ]
    }
   ],
   "source": [
    "df_test=Process().add_day_density(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-10 17:32:23,313 - process - Adding holidays\n"
     ]
    }
   ],
   "source": [
    "df_test=Process().add_holidays(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test=df_test.merge(pickup_density, how='left', on='pickup_cluster')\n",
    "df_test=df_test.merge(dropoff_density, how='left', on='dropoff_cluster')\n",
    "df_test['pickup_density'] = df_test.pickup_cluster_Count\n",
    "df_test['dropoff_density'] = df_test.dropoff_cluster_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>hour</th>\n",
       "      <th>...</th>\n",
       "      <th>longdistance</th>\n",
       "      <th>pickup_datetime_2</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pickup_datetime_2_Count</th>\n",
       "      <th>day_density</th>\n",
       "      <th>holiday</th>\n",
       "      <th>pickup_cluster_Count</th>\n",
       "      <th>dropoff_cluster_Count</th>\n",
       "      <th>pickup_density</th>\n",
       "      <th>dropoff_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>2015-01-27 13:08:00</td>\n",
       "      <td>-73.973320</td>\n",
       "      <td>40.763805</td>\n",
       "      <td>-73.981430</td>\n",
       "      <td>40.743835</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905146</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>2217</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>False</td>\n",
       "      <td>388696</td>\n",
       "      <td>376897</td>\n",
       "      <td>388696</td>\n",
       "      <td>376897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>2015-01-27 13:08:00</td>\n",
       "      <td>-73.986862</td>\n",
       "      <td>40.719383</td>\n",
       "      <td>-73.998886</td>\n",
       "      <td>40.739201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341968</td>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>2217</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>False</td>\n",
       "      <td>287873</td>\n",
       "      <td>258382</td>\n",
       "      <td>287873</td>\n",
       "      <td>258382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>2011-10-08 11:53:00</td>\n",
       "      <td>-73.982524</td>\n",
       "      <td>40.751260</td>\n",
       "      <td>-73.979654</td>\n",
       "      <td>40.746139</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320315</td>\n",
       "      <td>2011-10-08</td>\n",
       "      <td>1010</td>\n",
       "      <td>462</td>\n",
       "      <td>462</td>\n",
       "      <td>False</td>\n",
       "      <td>388696</td>\n",
       "      <td>376897</td>\n",
       "      <td>388696</td>\n",
       "      <td>376897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>2012-12-01 21:12:00</td>\n",
       "      <td>-73.981160</td>\n",
       "      <td>40.767807</td>\n",
       "      <td>-73.990448</td>\n",
       "      <td>40.751635</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036616</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>1430</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>False</td>\n",
       "      <td>388696</td>\n",
       "      <td>376897</td>\n",
       "      <td>388696</td>\n",
       "      <td>376897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>2012-12-01 21:12:00</td>\n",
       "      <td>-73.966046</td>\n",
       "      <td>40.789775</td>\n",
       "      <td>-73.988565</td>\n",
       "      <td>40.744427</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>2.513301</td>\n",
       "      <td>2012-12-01</td>\n",
       "      <td>1430</td>\n",
       "      <td>554</td>\n",
       "      <td>554</td>\n",
       "      <td>False</td>\n",
       "      <td>216721</td>\n",
       "      <td>376897</td>\n",
       "      <td>216721</td>\n",
       "      <td>376897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key     pickup_datetime  pickup_longitude  \\\n",
       "0  2015-01-27 13:08:24.0000002 2015-01-27 13:08:00        -73.973320   \n",
       "1  2015-01-27 13:08:24.0000003 2015-01-27 13:08:00        -73.986862   \n",
       "2  2011-10-08 11:53:44.0000002 2011-10-08 11:53:00        -73.982524   \n",
       "3  2012-12-01 21:12:12.0000002 2012-12-01 21:12:00        -73.981160   \n",
       "4  2012-12-01 21:12:12.0000003 2012-12-01 21:12:00        -73.966046   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.763805         -73.981430         40.743835                1   \n",
       "1        40.719383         -73.998886         40.739201                1   \n",
       "2        40.751260         -73.979654         40.746139                1   \n",
       "3        40.767807         -73.990448         40.751635                1   \n",
       "4        40.789775         -73.988565         40.744427                1   \n",
       "\n",
       "  pickup_cluster dropoff_cluster  hour       ...         longdistance  \\\n",
       "0              9               9    13       ...             0.905146   \n",
       "1              0               0    13       ...             1.341968   \n",
       "2              9               9    11       ...             0.320315   \n",
       "3              9               9    21       ...             1.036616   \n",
       "4              6               9    21       ...             2.513301   \n",
       "\n",
       "   pickup_datetime_2  Unnamed: 0  pickup_datetime_2_Count  day_density  \\\n",
       "0         2015-01-27        2217                      125          125   \n",
       "1         2015-01-27        2217                      125          125   \n",
       "2         2011-10-08        1010                      462          462   \n",
       "3         2012-12-01        1430                      554          554   \n",
       "4         2012-12-01        1430                      554          554   \n",
       "\n",
       "   holiday  pickup_cluster_Count dropoff_cluster_Count  pickup_density  \\\n",
       "0    False                388696                376897          388696   \n",
       "1    False                287873                258382          287873   \n",
       "2    False                388696                376897          388696   \n",
       "3    False                388696                376897          388696   \n",
       "4    False                216721                376897          216721   \n",
       "\n",
       "   dropoff_density  \n",
       "0           376897  \n",
       "1           258382  \n",
       "2           376897  \n",
       "3           376897  \n",
       "4           376897  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_1 = pd.get_dummies(df_test[['pickup_longitude',\n",
    "                                      'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "                                      'passenger_count', 'distance', 'year', 'month', 'day', 'hour',\n",
    "                                      'weekday', 'latdistance', 'longdistance', 'holiday', 'day_density',\n",
    "                                      'pickup_cluster', 'dropoff_cluster','pickup_density','dropoff_density']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_1['pickup_cluster_7']=0\n",
    "df_test_1['dropoff_cluster_7']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (df_test_1[[ 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude',\n",
    "       'dropoff_latitude', 'passenger_count', 'distance', 'year', 'month',\n",
    "       'day', 'hour', 'weekday', 'latdistance', 'longdistance', 'holiday',\n",
    "       'day_density', 'pickup_cluster_0', 'pickup_cluster_1',\n",
    "       'pickup_cluster_2', 'pickup_cluster_3', 'pickup_cluster_4',\n",
    "       'pickup_cluster_5', 'pickup_cluster_6', 'pickup_cluster_7',\n",
    "       'pickup_cluster_8', 'pickup_cluster_9', 'dropoff_cluster_0',\n",
    "       'dropoff_cluster_1', 'dropoff_cluster_2', 'dropoff_cluster_3',\n",
    "       'dropoff_cluster_4', 'dropoff_cluster_5', 'dropoff_cluster_6',\n",
    "       'dropoff_cluster_7', 'dropoff_cluster_8', 'dropoff_cluster_9','pickup_density','dropoff_density']]\n",
    "                 ._get_numeric_data()\n",
    "                 .as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914, 37)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = clf.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle/all\n"
     ]
    }
   ],
   "source": [
    "cd all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['preds']=predicted\n",
    "df_test_keys=df_test[['key','preds']]\n",
    "df_final=pd.read_csv('sample_submission.csv')\n",
    "df_final.fare_amount=df_final.merge(df_test_keys,on='key')['preds']\n",
    "df_final[['key','fare_amount']].to_csv('results_nathan.csv' ,  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb3_with_density_clusters_dummy_densities.pkl']"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pickle.dumps(clf)\n",
    "joblib.dump(clf, 'xgb3_with_density_clusters_dummy_densities.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=20, max_features=5, min_child_weight=1, missing=nan,\n",
       "       n_estimators=100, n_jobs=-1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.load('xgb3_with_density.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8921134"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914, 15)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_fi[:,:15].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled=scaler.transform(X)\n",
    "X_scaled_fi=FI*X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled_train=scaler.transform(X)\n",
    "X_scaled_fi_train=FI*X_scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9790787, 37)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_fi_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9790787,)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor(n_neighbors=3,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
       "          weights='uniform')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(X_scaled_fi_train[:,:15], y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=neigh.predict(X_scaled_fi[:,:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathantoubiana/Documents/Codes/Kaggle/all\n"
     ]
    }
   ],
   "source": [
    "cd all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['preds']=predicted\n",
    "df_test_keys=df_test[['key','preds']]\n",
    "df_final=pd.read_csv('sample_submission.csv')\n",
    "df_final.fare_amount=df_final.merge(df_test_keys,on='key')['preds']\n",
    "df_final[['key','fare_amount']].to_csv('results_nathan.csv' ,  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
